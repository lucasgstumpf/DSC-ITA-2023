{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the display format for floating-point numbers to suppress scientific notation\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 50)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/processed_data/merged_plate.csv')\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      1680295888000\n",
       " 1      1680126618000\n",
       " 2      1679907100000\n",
       " 3      1680283516000\n",
       " 4      1680283516000\n",
       "            ...      \n",
       " 827    1680307617000\n",
       " 828    1678366527000\n",
       " 829    1678366527000\n",
       " 830    1678366527000\n",
       " 831    1680004257000\n",
       " Name: dt_dep, Length: 832, dtype: int64,\n",
       " 0      1680300446000\n",
       " 1      1680130843000\n",
       " 2      1679914554000\n",
       " 3      1680289041000\n",
       " 4      1680289041000\n",
       "            ...      \n",
       " 827    1680310619000\n",
       " 828    1678370919000\n",
       " 829    1678370919000\n",
       " 830    1678370919000\n",
       " 831    1680008669000\n",
       " Name: dt_arr, Length: 832, dtype: int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['dt_dep'], df_train['dt_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metar_windDirection    832\n",
       "metar_weather          714\n",
       "metaf_weather          652\n",
       "metaf_skyFeet          384\n",
       "metaf_sky              384\n",
       "metar_skyFeet          164\n",
       "metar_sky              163\n",
       "metar_windVelocity      58\n",
       "metar_visibility        58\n",
       "metar_pressure          58\n",
       "metar_type              52\n",
       "metar_hora_formated     52\n",
       "metar_station.1         52\n",
       "metar_dew_point         52\n",
       "metar_station           52\n",
       "metaf_type              41\n",
       "metaf_hora_formated     41\n",
       "metaf_station.1         41\n",
       "metaf_dew_point         41\n",
       "metaf_windDirection     41\n",
       "metaf_windVelocity      41\n",
       "metaf_visibility        41\n",
       "metaf_pressure          41\n",
       "metaf_station           41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create a function that counts the rows that has at least one null or nan value sorting by the number of null values\n",
    "## give me the name of the columns and its number of null values\n",
    "def count_null(df):\n",
    "    null_count = df.isnull().sum().sort_values(ascending=False)\n",
    "    null_count = null_count[null_count > 0]\n",
    "    return null_count\n",
    "\n",
    "count_null(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40039, 46)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especifica o delimitador como ponto e vírgula\n",
    "delimiter = ';'\n",
    "\n",
    "# Lê o arquivo CSV, informando o delimitador e o header está na primeira linha\n",
    "df_test = pd.read_csv('../data/processed_data/idsc_dataset_plate.csv')\n",
    "\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metar_windDirection    40039\n",
       "metar_weather          35860\n",
       "metaf_weather          34529\n",
       "hora_tcr               30620\n",
       "aero_tcr               30620\n",
       "metaf_skyFeet          27489\n",
       "metaf_sky              27489\n",
       "metar_skyFeet          18839\n",
       "metar_sky              17866\n",
       "metaf_windVelocity      6291\n",
       "metaf_visibility        6291\n",
       "metaf_pressure          6291\n",
       "metaf_windDirection     6251\n",
       "metaf_station.1         6251\n",
       "metaf_hora_formated     6251\n",
       "metaf_type              6251\n",
       "metaf_station           6251\n",
       "metaf_dew_point         6251\n",
       "aero_metaf              5334\n",
       "metaf                   5334\n",
       "hora_metaf              5334\n",
       "metar_pressure          2726\n",
       "metar_visibility        2726\n",
       "metar_windVelocity      2726\n",
       "snapshot_radar          2574\n",
       "metar_station.1         2285\n",
       "metar_dew_point         2285\n",
       "metar_type              2284\n",
       "metar_hora_formated     2284\n",
       "metar_station           2284\n",
       "path                    1169\n",
       "troca                    981\n",
       "hora_tcp                 981\n",
       "aero_metar               926\n",
       "metar                    926\n",
       "hora_metar               926\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_null(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Unnamed: 0.1', 'Unnamed: 0', 'flightid', 'origem', 'destino', 'dt_dep',\n",
       "        'dt_arr', 'dt_dep_formatted', 'dt_arr_formatted', 'hora_real',\n",
       "        'nova_cabeceira', 'antiga_cabeceira', 'aero_real',\n",
       "        'hora_formatted_real', 'hora_prev', 'troca', 'aero_prev',\n",
       "        'hora_formatted_prev', 'hora_metar', 'metar', 'aero_metar',\n",
       "        'hora_formatted_metar', 'hora_metaf', 'metaf', 'aero_metaf',\n",
       "        'hora_formatted_metaf', 'metar_station', 'metar_type',\n",
       "        'metar_hora_formated', 'metar_station.1', 'metar_dew_point',\n",
       "        'metar_windDirection', 'metar_windVelocity', 'metar_visibility',\n",
       "        'metar_pressure', 'metar_weather', 'metar_sky', 'metar_skyFeet',\n",
       "        'metaf_station', 'metaf_type', 'metaf_hora_formated', 'metaf_station.1',\n",
       "        'metaf_dew_point', 'metaf_windDirection', 'metaf_windVelocity',\n",
       "        'metaf_visibility', 'metaf_pressure', 'metaf_weather', 'metaf_sky',\n",
       "        'metaf_skyFeet'],\n",
       "       dtype='object'),\n",
       " Index(['Unnamed: 0', 'flightid', 'origem', 'destino', 'hora_ref', 'dt_dep',\n",
       "        'snapshot_radar', 'path', 'hora_esperas', 'esperas', 'aero_esperas',\n",
       "        'hora_metaf', 'metaf', 'aero_metaf', 'hora_metar', 'metar',\n",
       "        'aero_metar', 'hora_tcp', 'troca', 'aero_tcp', 'hora_tcr', 'aero_tcr',\n",
       "        'metar_station', 'metar_type', 'metar_hora_formated', 'metar_station.1',\n",
       "        'metar_dew_point', 'metar_windDirection', 'metar_windVelocity',\n",
       "        'metar_visibility', 'metar_pressure', 'metar_weather', 'metar_sky',\n",
       "        'metar_skyFeet', 'metaf_station', 'metaf_type', 'metaf_hora_formated',\n",
       "        'metaf_station.1', 'metaf_dew_point', 'metaf_windDirection',\n",
       "        'metaf_windVelocity', 'metaf_visibility', 'metaf_pressure',\n",
       "        'metaf_weather', 'metaf_sky', 'metaf_skyFeet'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns, df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_null_values(df):\n",
    "    # Replace all null or NaN values with 0\n",
    "    df_filled = df.fillna(-1)\n",
    "    return df_filled\n",
    "\n",
    "df_train = replace_null_values(df_train)\n",
    "df_test = replace_null_values(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40039, 46), (832, 50))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['origem', 'destino', 'dt_dep', 'aero_metaf', 'aero_metar',\n",
       "        'metar_station', 'metar_type', 'metar_station.1', 'metar_dew_point',\n",
       "        'metar_windDirection', 'metar_windVelocity', 'metar_visibility',\n",
       "        'metar_pressure', 'metar_weather', 'metar_sky', 'metar_skyFeet',\n",
       "        'metaf_station', 'metaf_type', 'metaf_station.1', 'metaf_dew_point',\n",
       "        'metaf_windDirection', 'metaf_windVelocity', 'metaf_visibility',\n",
       "        'metaf_pressure', 'metaf_weather', 'metaf_sky', 'metaf_skyFeet'],\n",
       "       dtype='object'),\n",
       " Index(['Unnamed: 0', 'flightid', 'origem', 'destino', 'hora_ref', 'dt_dep',\n",
       "        'snapshot_radar', 'path', 'hora_esperas', 'esperas', 'aero_esperas',\n",
       "        'hora_metaf', 'metaf', 'aero_metaf', 'hora_metar', 'metar',\n",
       "        'aero_metar', 'hora_tcp', 'troca', 'aero_tcp', 'hora_tcr', 'aero_tcr',\n",
       "        'metar_station', 'metar_type', 'metar_hora_formated', 'metar_station.1',\n",
       "        'metar_dew_point', 'metar_windDirection', 'metar_windVelocity',\n",
       "        'metar_visibility', 'metar_pressure', 'metar_weather', 'metar_sky',\n",
       "        'metar_skyFeet', 'metaf_station', 'metaf_type', 'metaf_hora_formated',\n",
       "        'metaf_station.1', 'metaf_dew_point', 'metaf_windDirection',\n",
       "        'metaf_windVelocity', 'metaf_visibility', 'metaf_pressure',\n",
       "        'metaf_weather', 'metaf_sky', 'metaf_skyFeet'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns, df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((832, 26), (832,), (40039, 26))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop([\n",
    "    'dt_arr', 'dt_arr_formatted', 'Unnamed: 0.1', 'dt_dep_formatted', 'hora_real',\n",
    "    'hora_formatted_real', 'hora_formatted_prev', 'hora_formatted_metar', 'hora_formatted_metaf',\n",
    "    'metar_hora_formated', 'flightid', 'Unnamed: 0', 'hora_prev', 'metaf_hora_formated', 'hora_metar', \n",
    "    'hora_metaf', 'metaf', 'nova_cabeceira', 'antiga_cabeceira', 'metar', 'aero_prev', 'troca', 'aero_real',\n",
    "    'dt_dep'\n",
    "\n",
    "], axis = 1)\n",
    "\n",
    "X_test = df_test.drop([\n",
    "    'Unnamed: 0', 'flightid', 'snapshot_radar', 'path', 'hora_ref', 'hora_tcp', 'metaf_hora_formated',\n",
    "    'hora_metaf', 'hora_esperas', 'hora_metar', 'metaf', 'hora_tcr', 'metar', 'esperas', 'aero_esperas',\n",
    "    'aero_tcp', 'aero_tcr', 'troca', 'metar_hora_formated', 'dt_dep'\n",
    "], axis = 1)\n",
    "\n",
    "y_train = df_train['dt_arr']\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['origem', 'destino', 'aero_metar', 'aero_metaf', 'metar_station',\n",
       "        'metar_type', 'metar_station.1', 'metar_dew_point',\n",
       "        'metar_windDirection', 'metar_windVelocity', 'metar_visibility',\n",
       "        'metar_pressure', 'metar_weather', 'metar_sky', 'metar_skyFeet',\n",
       "        'metaf_station', 'metaf_type', 'metaf_station.1', 'metaf_dew_point',\n",
       "        'metaf_windDirection', 'metaf_windVelocity', 'metaf_visibility',\n",
       "        'metaf_pressure', 'metaf_weather', 'metaf_sky', 'metaf_skyFeet'],\n",
       "       dtype='object'),\n",
       " Index(['origem', 'destino', 'aero_metaf', 'aero_metar', 'metar_station',\n",
       "        'metar_type', 'metar_station.1', 'metar_dew_point',\n",
       "        'metar_windDirection', 'metar_windVelocity', 'metar_visibility',\n",
       "        'metar_pressure', 'metar_weather', 'metar_sky', 'metar_skyFeet',\n",
       "        'metaf_station', 'metaf_type', 'metaf_station.1', 'metaf_dew_point',\n",
       "        'metaf_windDirection', 'metaf_windVelocity', 'metaf_visibility',\n",
       "        'metaf_pressure', 'metaf_weather', 'metaf_sky', 'metaf_skyFeet'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns, X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['origem', 'destino', 'aero_metaf', 'aero_metar', 'metar_station',\n",
       "       'metar_type', 'metar_station.1', 'metar_dew_point',\n",
       "       'metar_windDirection', 'metar_windVelocity', 'metar_visibility',\n",
       "       'metar_pressure', 'metar_weather', 'metar_sky', 'metar_skyFeet',\n",
       "       'metaf_station', 'metaf_type', 'metaf_station.1', 'metaf_dew_point',\n",
       "       'metaf_windDirection', 'metaf_windVelocity', 'metaf_visibility',\n",
       "       'metaf_pressure', 'metaf_weather', 'metaf_sky', 'metaf_skyFeet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_column_order(df, coluna1, coluna2):\n",
    "    colunas = df.columns.tolist()\n",
    "    \n",
    "    if coluna1 not in colunas or coluna2 not in colunas:\n",
    "        print(\"Uma ou ambas as colunas não estão presentes no DataFrame.\")\n",
    "        return df\n",
    "    \n",
    "    indice_coluna1 = colunas.index(coluna1)\n",
    "    indice_coluna2 = colunas.index(coluna2)\n",
    "    \n",
    "    colunas[indice_coluna1], colunas[indice_coluna2] = colunas[indice_coluna2], colunas[indice_coluna1]\n",
    "    \n",
    "    return df[colunas]\n",
    "\n",
    "X_train = change_column_order(X_train, 'aero_metaf', 'aero_metar')\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "[1.6790706e+12 1.6801369e+12 1.6797494e+12 ... 1.6798494e+12 1.6790366e+12\n",
      " 1.6801902e+12] (40039,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression  # Replace with your regression model of choice\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def get_numerical_variables(df):\n",
    "    \"\"\"\n",
    "    Get a list of numerical variable names from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        numerical_vars (list): List of numerical variable names.\n",
    "    \"\"\"\n",
    "    numerical_vars = df.select_dtypes(include=['number', 'int64', 'float64']).columns.tolist()\n",
    "    return numerical_vars\n",
    "\n",
    "def get_categorical_variables(df):\n",
    "    \"\"\"\n",
    "    Get a list of categorical variable names from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        categorical_vars (list): List of categorical variable names.\n",
    "    \"\"\"\n",
    "    categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    return categorical_vars\n",
    "\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train, categorical_vars=None, numerical_vars=None):\n",
    "    \"\"\"\n",
    "    Preprocess the data for modeling.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training data features.\n",
    "        X_test (pd.DataFrame): Test data features.\n",
    "        y_train (pd.Series): Target variable for training.\n",
    "        categorical_vars (list): List of categorical variables (default is None).\n",
    "        numerical_vars (list): List of numerical variables (default is None).\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): Preprocessed training data features.\n",
    "        X_test (pd.DataFrame): Preprocessed test data features.\n",
    "        y_train (pd.Series): Target variable for training.\n",
    "        preprocessor (ColumnTransformer): Data preprocessor.\n",
    "    \"\"\"\n",
    "    # Ensure categorical and numerical variables are defined\n",
    "    if categorical_vars is None:\n",
    "        categorical_vars = []\n",
    "    if numerical_vars is None:\n",
    "        numerical_vars = []\n",
    "\n",
    "    # Convert categorical variables to strings\n",
    "    X_train[categorical_vars] = X_train[categorical_vars].astype(str)\n",
    "    X_test[categorical_vars] = X_test[categorical_vars].astype(str)\n",
    "\n",
    "    # Create data preprocessor\n",
    "    preprocessor = encode_data(categorical_vars, numerical_vars)\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test data\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, preprocessor\n",
    "\n",
    "def encode_data(categorical_vars, numerical_vars):\n",
    "    \"\"\"\n",
    "    Encode categorical variables and scale numerical variables.\n",
    "\n",
    "    Args:\n",
    "        categorical_vars (list): List of categorical variables.\n",
    "        numerical_vars (list): List of numerical variables.\n",
    "\n",
    "    Returns:\n",
    "        preprocessor (ColumnTransformer): Data preprocessor.\n",
    "    \"\"\"\n",
    "    # Create transformers for categorical and numerical variables\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_vars),\n",
    "            ('num', numerical_transformer, numerical_vars)\n",
    "        ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "def select_best_model(X_train, y_train, param_grid, num_folds=5):\n",
    "    \"\"\"\n",
    "    Select the best model using GridSearchCV.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Preprocessed training data features.\n",
    "        y_train (pd.Series): Target variable for training.\n",
    "        param_grid (dict): Hyperparameter grid for model selection.\n",
    "        num_folds (int): Number of cross-validation folds (default is 5).\n",
    "\n",
    "    Returns:\n",
    "        best_estimator (Pipeline): Best model selected by GridSearchCV.\n",
    "    \"\"\"\n",
    "    # Create the model pipeline\n",
    "    reg_model = Pipeline([\n",
    "        ('model', XGBRegressor())\n",
    "    ])\n",
    "\n",
    "    # Create GridSearchCV with the model and hyperparameters\n",
    "    grid_search = GridSearchCV(estimator=reg_model, param_grid=param_grid, cv=num_folds, n_jobs=-1, verbose=2)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimator from the grid search\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    return best_estimator\n",
    "\n",
    "def make_predictions(best_estimator, X_test):\n",
    "    \"\"\"\n",
    "    Make predictions using the best model.\n",
    "\n",
    "    Args:\n",
    "        best_estimator (Pipeline): Best model selected by GridSearchCV.\n",
    "        X_test (pd.DataFrame): Preprocessed test data features.\n",
    "\n",
    "    Returns:\n",
    "        y_pred (np.array): Predicted target variable.\n",
    "    \"\"\"\n",
    "    # Make predictions on the test set using the best estimator\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# Example usage:\n",
    "np.random.seed(42)\n",
    "\n",
    "numerical_variables = get_numerical_variables(X_train)\n",
    "categorical_variables = get_categorical_variables(X_train)\n",
    "\n",
    "X_train, X_test, y_train, preprocessor = preprocess_data(X_train, X_test, y_train, categorical_vars=categorical_variables, numerical_vars=numerical_variables)\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 500, 1000],\n",
    "    'model__max_depth': [3, 4, 5, 6],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__min_child_weight': [1, 2, 3],\n",
    "    'model__subsample': [0.8, 0.9, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "best_estimator = select_best_model(X_train, y_train, param_grid, num_folds=5)\n",
    "\n",
    "y_pred = make_predictions(best_estimator, X_test)\n",
    "print(y_pred, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4f0356600f61e3fcbea8ed8a137a2423</td>\n",
       "      <td>3888016583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>865dbbbe74bebea18a71f24342516ff0</td>\n",
       "      <td>3889125387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803af9cfc6a2c74d188481e3ffd848e</td>\n",
       "      <td>3888732620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6af733a687f904183efd149ec713be5</td>\n",
       "      <td>3888295162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6117f9ac60b7f66b740c9130be433313</td>\n",
       "      <td>3888697635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID    solution\n",
       "0  4f0356600f61e3fcbea8ed8a137a2423  3888016583\n",
       "1  865dbbbe74bebea18a71f24342516ff0  3889125387\n",
       "2  1803af9cfc6a2c74d188481e3ffd848e  3888732620\n",
       "3  f6af733a687f904183efd149ec713be5  3888295162\n",
       "4  6117f9ac60b7f66b740c9130be433313  3888697635"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_timestamps_to_datetime(timestamps, unit='ms'):\n",
    "    \"\"\"\n",
    "    Converts a series of timestamps to datetime objects.\n",
    "\n",
    "    Args:\n",
    "        timestamps (pd.Series): Series of timestamps.\n",
    "        unit (str): Unit of the timestamps (default is 'ms' for milliseconds).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series of datetime objects.\n",
    "    \"\"\"\n",
    "    timestamps = pd.to_datetime(timestamps, unit=unit)\n",
    "    return timestamps\n",
    "\n",
    "def calculate_time_difference_in_seconds(datetime_series1, datetime_series2):\n",
    "    \"\"\"\n",
    "    Calculates the time difference in seconds between two series of datetime objects.\n",
    "\n",
    "    Args:\n",
    "        datetime_series1 (pd.Series): First series of datetime objects.\n",
    "        datetime_series2 (pd.Series): Second series of datetime objects.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Series of time differences in seconds.\n",
    "    \"\"\"\n",
    "    time_difference = (datetime_series1 - datetime_series2).dt.total_seconds()\n",
    "    return time_difference\n",
    "\n",
    "def process_data(df_test, y_pred):\n",
    "    \"\"\"\n",
    "    Process the data and return a DataFrame with flight IDs and predicted time differences.\n",
    "\n",
    "    Args:\n",
    "        df_test (pd.DataFrame): DataFrame containing flight data.\n",
    "        y_pred (pd.Series): Series containing predicted timestamps.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with flight IDs and predicted time differences as int64.\n",
    "    \"\"\"\n",
    "    # Convert 'y_pred' to datetime objects\n",
    "    y_pred_datetime = convert_timestamps_to_datetime(y_pred)\n",
    "\n",
    "    # Convert 'dt_dep' to datetime objects\n",
    "    df_test['dt_dep'] = pd.to_datetime(df_test['dt_dep'], format='%H:%M:%S')\n",
    "\n",
    "    # Calculate time difference in seconds\n",
    "    delta_seconds = calculate_time_difference_in_seconds(y_pred_datetime, df_test['dt_dep'])\n",
    "\n",
    "    # Round the delta_seconds to the nearest integer and cast to int64\n",
    "    delta_seconds = delta_seconds.round().astype('int64')\n",
    "\n",
    "    # Create a DataFrame with 'flightid' and 'predicted time of arrival' (as int64)\n",
    "    result_df = pd.DataFrame({\n",
    "        'ID': df_test['flightid'],\n",
    "        'solution': delta_seconds\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "result_df = process_data(df_test, y_pred)\n",
    "result_df.to_csv('predicted_arrival_times.csv', index=False)\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3888912693    3\n",
       "3888649720    3\n",
       "3888768022    3\n",
       "3888830179    3\n",
       "3888418560    3\n",
       "             ..\n",
       "3889175558    1\n",
       "3888881450    1\n",
       "3887409293    1\n",
       "3888370559    1\n",
       "3889175463    1\n",
       "Name: solution, Length: 39510, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['solution'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
